# Multi-Link Downloader (Async + Resume Support)

A simple Python script to download multiple files concurrently with resume support using `aiohttp` and `asyncio`.

## ğŸš€ Features

- Downloads multiple files at the same time (up to 5 concurrent downloads)
- Supports resuming downloads if they were interrupted
- Automatically saves all files to the `downloads/` folder
- Handles 403 errors using proper headers (User-Agent and Referer)

## ğŸ“¦ Requirements

- Python 3.7+
- Install dependencies:

```bash
pip install aiohttp aiofiles
```

## ğŸ“‚ How to Use

1. Put all your download links (one per line) into a file named `links.txt`.

   **Example `links.txt`:**
   ```
   https://example.com/file1.mp4
   https://example.com/file2.mp4
   ```

2. Run the script:
   ```bash
   python main.py
   ```

3. All downloaded files will be saved in the `downloads/` folder.

## ğŸ“ Notes

- Make sure your links are direct downloadable URLs.
- If your internet disconnects, just re-run the script â€” it will continue incomplete downloads automatically (if the server supports it).
